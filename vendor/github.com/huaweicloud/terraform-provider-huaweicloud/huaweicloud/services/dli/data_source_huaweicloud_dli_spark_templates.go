// Generated by PMS #89
package dli

import (
	"context"

	"github.com/hashicorp/go-multierror"
	"github.com/hashicorp/go-uuid"
	"github.com/hashicorp/terraform-plugin-sdk/v2/diag"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/schema"
	"github.com/tidwall/gjson"

	"github.com/huaweicloud/terraform-provider-huaweicloud/huaweicloud/config"
	"github.com/huaweicloud/terraform-provider-huaweicloud/huaweicloud/helper/filters"
	"github.com/huaweicloud/terraform-provider-huaweicloud/huaweicloud/helper/httphelper"
	"github.com/huaweicloud/terraform-provider-huaweicloud/huaweicloud/helper/schemas"
)

func DataSourceDliSparkTemplates() *schema.Resource {
	return &schema.Resource{
		ReadContext: dataSourceDliSparkTemplatesRead,

		Schema: map[string]*schema.Schema{
			"region": {
				Type:        schema.TypeString,
				Optional:    true,
				Computed:    true,
				Description: `Specifies the region in which to query the resource.`,
			},
			"template_id": {
				Type:        schema.TypeString,
				Optional:    true,
				Description: `Specifies the ID of the spark template to be queried.`,
			},
			"name": {
				Type:        schema.TypeString,
				Optional:    true,
				Description: `Specifies the name of the spark template to be queried.`,
			},
			"group": {
				Type:        schema.TypeString,
				Optional:    true,
				Description: `Specifies the group name to which the spark templates belong.`,
			},
			"templates": {
				Type:        schema.TypeList,
				Computed:    true,
				Description: `All templates that match the filter parameters.`,
				Elem: &schema.Resource{
					Schema: map[string]*schema.Schema{
						"id": {
							Type:        schema.TypeString,
							Computed:    true,
							Description: `The ID of template.`,
						},
						"name": {
							Type:        schema.TypeString,
							Computed:    true,
							Description: `The name of template.`,
						},
						"group": {
							Type:        schema.TypeString,
							Computed:    true,
							Description: `The group name to which the spark template belongs.`,
						},
						"description": {
							Type:        schema.TypeString,
							Computed:    true,
							Description: `The description of template.`,
						},
						"body": {
							Type:        schema.TypeList,
							Computed:    true,
							Description: `The body of template.`,
							Elem: &schema.Resource{
								Schema: map[string]*schema.Schema{
									"name": {
										Type:        schema.TypeString,
										Computed:    true,
										Description: `The spark job name.`,
									},
									"dependent_packages": {
										Type:        schema.TypeList,
										Computed:    true,
										Description: `The list of package resource objects.`,
										Elem:        temBodDepPacElem(),
									},
									"app_parameters": {
										Type:        schema.TypeList,
										Computed:    true,
										Elem:        &schema.Schema{Type: schema.TypeString},
										Description: `The input parameters of the main class, that is application parameters.`,
									},
									"obs_bucket": {
										Type:        schema.TypeString,
										Computed:    true,
										Description: `The OBS bucket for storing the spark jobs.`,
									},
									"auto_recovery": {
										Type:        schema.TypeBool,
										Computed:    true,
										Description: `Indicates whether to enable the retry function.`,
									},
									"max_retry_times": {
										Type:        schema.TypeInt,
										Computed:    true,
										Description: `The maximum number of retries.`,
									},
									"jars": {
										Type:        schema.TypeList,
										Computed:    true,
										Elem:        &schema.Schema{Type: schema.TypeString},
										Description: `The name of the resource package of type jar upload to the DLI resource management system.`,
									},
									"configurations": {
										Type:        schema.TypeMap,
										Computed:    true,
										Elem:        &schema.Schema{Type: schema.TypeString},
										Description: `The configuration items of the DLI spark.`,
									},
									"executor_memory": {
										Type:        schema.TypeString,
										Computed:    true,
										Description: `The executor memory of the spark application.`,
									},
									"queue_name": {
										Type:        schema.TypeString,
										Computed:    true,
										Description: `The DLI queue name.`,
									},
									"main_class": {
										Type:        schema.TypeString,
										Computed:    true,
										Description: `The spark main class of the template.`,
									},
									"python_files": {
										Type:        schema.TypeList,
										Computed:    true,
										Elem:        &schema.Schema{Type: schema.TypeString},
										Description: `Name of the package that is of the PyFile type.`,
									},
									"files": {
										Type:        schema.TypeList,
										Computed:    true,
										Elem:        &schema.Schema{Type: schema.TypeString},
										Description: `The name of the resource package of type file upload to the DLI resource management system.`,
									},
									"modules": {
										Type:        schema.TypeList,
										Computed:    true,
										Elem:        &schema.Schema{Type: schema.TypeString},
										Description: `The name of the dependent system resource module.`,
									},
									"driver_memory": {
										Type:        schema.TypeString,
										Computed:    true,
										Description: `The driver memory of the spark application.`,
									},
									"executor_cores": {
										Type:        schema.TypeInt,
										Computed:    true,
										Description: `The number of CPU cores of each executor in the spark application.`,
									},
									"app_name": {
										Type:        schema.TypeString,
										Computed:    true,
										Description: `The name of the uploaded JAR or pyFile type package.`,
									},
									"specification": {
										Type:        schema.TypeString,
										Computed:    true,
										Description: `The compute resource type. Currently, resource types A, B, and C are available.`,
									},
									"resources": {
										Type:        schema.TypeList,
										Computed:    true,
										Description: `The list of resource objects.`,
										Elem:        temBodResElem(),
									},
									"driver_cores": {
										Type:        schema.TypeInt,
										Computed:    true,
										Description: `The number of CPU cores of the spark application driver.`,
									},
									"num_executors": {
										Type:        schema.TypeInt,
										Computed:    true,
										Description: `The number of executors in a spark application.`,
									},
								},
							},
						},
					},
				},
			},
		},
	}
}

// temBodResElem
// The Elem of "templates.body.resources"
func temBodResElem() *schema.Resource {
	return &schema.Resource{
		Schema: map[string]*schema.Schema{
			"name": {
				Type:        schema.TypeString,
				Computed:    true,
				Description: `The name of resource.`,
			},
			"type": {
				Type:        schema.TypeString,
				Computed:    true,
				Description: `The type of resource.`,
			},
		},
	}
}

// temBodDepPacElem
// The Elem of "templates.body.dependent_packages"
func temBodDepPacElem() *schema.Resource {
	return &schema.Resource{
		Schema: map[string]*schema.Schema{
			"name": {
				Type:        schema.TypeString,
				Computed:    true,
				Description: `The name of a user group.`,
			},
			"resources": {
				Type:        schema.TypeList,
				Computed:    true,
				Description: `The resources of a user group.`,
				Elem: &schema.Resource{
					Schema: map[string]*schema.Schema{
						"name": {
							Type:        schema.TypeString,
							Computed:    true,
							Description: `The name of resource.`,
						},
						"type": {
							Type:        schema.TypeString,
							Computed:    true,
							Description: `The type of resource.`,
						},
					},
				},
			},
		},
	}
}

type SparkTemplatesDSWrapper struct {
	*schemas.ResourceDataWrapper
	Config *config.Config
}

func newSparkTemplatesDSWrapper(d *schema.ResourceData, meta interface{}) *SparkTemplatesDSWrapper {
	return &SparkTemplatesDSWrapper{
		ResourceDataWrapper: schemas.NewSchemaWrapper(d),
		Config:              meta.(*config.Config),
	}
}

func dataSourceDliSparkTemplatesRead(_ context.Context, d *schema.ResourceData, meta interface{}) diag.Diagnostics {
	wrapper := newSparkTemplatesDSWrapper(d, meta)
	lisSpaJobTemRst, err := wrapper.ListSparkJobTemplates()
	if err != nil {
		return diag.FromErr(err)
	}

	id, err := uuid.GenerateUUID()
	if err != nil {
		return diag.FromErr(err)
	}
	d.SetId(id)

	err = wrapper.listSparkJobTemplatesToSchema(lisSpaJobTemRst)
	if err != nil {
		return diag.FromErr(err)
	}

	return nil
}

// @API DLI GET /v3/{project_id}/templates
func (w *SparkTemplatesDSWrapper) ListSparkJobTemplates() (*gjson.Result, error) {
	client, err := w.NewClient(w.Config, "dli")
	if err != nil {
		return nil, err
	}

	uri := "/v3/{project_id}/templates"
	params := map[string]any{
		"type": "SPARK",
	}
	return httphelper.New(client).
		Method("GET").
		URI(uri).
		Query(params).
		PageSizePager("templates", "current-page", "page-size", 50).
		Filter(
			filters.New().From("templates").
				Where("id", "=", w.Get("template_id")).
				Where("name", "=", w.Get("name")).
				Where("group", "=", w.Get("group")),
		).
		Request().
		Result()
}

func (w *SparkTemplatesDSWrapper) listSparkJobTemplatesToSchema(body *gjson.Result) error {
	d := w.ResourceData
	mErr := multierror.Append(nil,
		d.Set("region", w.Config.GetRegion(w.ResourceData)),
		d.Set("templates", schemas.SliceToList(body.Get("templates"),
			func(template gjson.Result) any {
				return map[string]any{
					"id":          template.Get("id").Value(),
					"name":        template.Get("name").Value(),
					"group":       template.Get("group").Value(),
					"description": template.Get("description").Value(),
					"body": schemas.SliceToList(template.Get("body"),
						func(body gjson.Result) any {
							return map[string]any{
								"name":               body.Get("name").Value(),
								"dependent_packages": w.setTemBodGro(body),
								"app_parameters":     schemas.SliceToStrList(body.Get("args")),
								"obs_bucket":         body.Get("obs_bucket").Value(),
								"auto_recovery":      body.Get("auto_recovery").Value(),
								"max_retry_times":    body.Get("max_retry_times").Value(),
								"jars":               schemas.SliceToStrList(body.Get("jars")),
								"configurations":     schemas.MapToStrMap(body.Get("conf")),
								"executor_memory":    body.Get("executorMemory").Value(),
								"queue_name":         body.Get("queue").Value(),
								"main_class":         body.Get("className").Value(),
								"python_files":       schemas.SliceToStrList(body.Get("pyFiles")),
								"files":              schemas.SliceToStrList(body.Get("files")),
								"modules":            schemas.SliceToStrList(body.Get("modules")),
								"driver_memory":      body.Get("driverMemory").Value(),
								"executor_cores":     body.Get("executorCores").Value(),
								"app_name":           body.Get("file").Value(),
								"specification":      body.Get("sc_type").Value(),
								"resources":          w.setTemBodRes(body),
								"driver_cores":       body.Get("driverCores").Value(),
								"num_executors":      body.Get("numExecutors").Value(),
							}
						},
					),
				}
			},
		)),
	)
	return mErr.ErrorOrNil()
}

func (*SparkTemplatesDSWrapper) setTemBodGro(body gjson.Result) any {
	return schemas.SliceToList(body.Get("groups"), func(depPac gjson.Result) any {
		return map[string]any{
			"name": depPac.Get("name").Value(),
			"resources": schemas.SliceToList(depPac.Get("resources"),
				func(resource gjson.Result) any {
					return map[string]any{
						"name": resource.Get("name").Value(),
						"type": resource.Get("type").Value(),
					}
				},
			),
		}
	})
}

func (*SparkTemplatesDSWrapper) setTemBodRes(body gjson.Result) any {
	return schemas.SliceToList(body.Get("resources"), func(resource gjson.Result) any {
		return map[string]any{
			"name": resource.Get("name").Value(),
			"type": resource.Get("type").Value(),
		}
	})
}
